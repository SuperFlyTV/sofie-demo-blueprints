{"searchDocs":[{"title":"AdLibs","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/adlibs","content":"AdLibs AdLibs are pieces or actions that can be taken by the user during a show. Sofie provides two different types of AdLibs: AdLib PiecesAdLib Actions Both can have two context, either belong to a segment/part or have a global context (which is still limited to the Rundown they are in! It's important to keep in mind that a Global AdLib will not be available for an entire RundownPlaylist, it's tied to a given Rundown in that playlist.) AdLib Pieces are the simple way of improvising during a show, they simply insert a piece into it's layer. AdLib Actions however as the name suggests are executing actions with logic inside your blueprint. Usually the result of an AdLib Action is a new piece or part in the rundown, but it can also change the current pieces and parts in the rundown. You can use it to alter the content of these pieces as well and add checks when executing an Action. We recommend only using AdLib actions if you are creating a new system, as it's much more flexible and is able to do everything AdLib Pieces did, so when you decide that you need more functionality it's less work to extend them.","keywords":"","version":"Next"},{"title":"Global Adlibs","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/adlibs/global_adlibs","content":"Global Adlibs Global Adlibs are Adlibs that are available to any Rundown created with this set of Blueprints. They can be accessed by opening the drawer at the bottom of the Rundown UI. Currently, the Demo Blueprints specify 5 Global Adlibs: Last Remote Shows the last-used Remote input on-air Last DVE Shows the last-used DVE configuration on-air Camera 1 Shows Camera 1 on-air Camera 2 Shows Camera 2 on-air Remote 1 Shows Remote 1 on-air","keywords":"","version":"Next"},{"title":"Global Configurations","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/global_configurations","content":"","keywords":"","version":"Next"},{"title":"Studio Configuration​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#studio-configuration","content":" These are the config parameters for the Studio. They can be accessed from the Studio Blueprint Configuration page.  ","version":"Next","tagName":"h2"},{"title":"Vision Mixer Type​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#vision-mixer-type","content":" This is where you can choose between using a Blackmagic ATEM or vMix.  ","version":"Next","tagName":"h3"},{"title":"ATEM Sources​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#atem-sources","content":" This is how the blueprints know which ATEM inputs correspond to cameras, remotes, graphics, etc. Configuring these is required. See the README for more information.  ","version":"Next","tagName":"h3"},{"title":"ATEM Outputs​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#atem-outputs","content":" This is where you can configure fixed aux outputs for your ATEM, such as always outputting Camera 1 to Aux 1, Remote 1 to Aux 2, etc.  ","version":"Next","tagName":"h3"},{"title":"vMix Sources​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#vmix-sources","content":" This is how the blueprints know which vMix inputs correspond to cameras, remotes, graphics, etc. Configuring these is required. See the README for more information.  ","version":"Next","tagName":"h3"},{"title":"Sisyfos Sources​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#sisyfos-sources","content":" This is how the blueprints know which audio channels correspond to the host, guests, remotes, and VTs. Used by the blueprints to automatically mute/unmute these channels as-needed.  ","version":"Next","tagName":"h3"},{"title":"Preview Renderer​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#preview-renderer","content":" For internal use at NRK only.  ","version":"Next","tagName":"h3"},{"title":"CasparCG Latency​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#casparcg-latency","content":" This is how the blueprints know how much to preroll certain pieces by to account for Caspar's inherent SDI latency. The delay should be provided in milliseconds, not frames.  ","version":"Next","tagName":"h3"},{"title":"Showstyle Configuration​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#showstyle-configuration","content":" These are the config parameters for the Showstyle. They can be accessed from the Showstyle Blueprint Configuration page.  ","version":"Next","tagName":"h2"},{"title":"DVE Presets​","type":1,"pageTitle":"Global Configurations","url":"/sofie-demo-blueprints/docs/global_configurations#dve-presets","content":" This is where the DVE configuration for Split Pieces is defined. Default values are provided for a &quot;two split&quot; setup. These parameters only apply to ATEM vision mixers. ","version":"Next","tagName":"h3"},{"title":"Creating a Global AdLib Action","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions","content":"","keywords":"","version":"Next"},{"title":"Step 1: Add a new ActionId​","type":1,"pageTitle":"Creating a Global AdLib Action","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions#step-1-add-a-new-actionid","content":" The first step is to come up with an identifier for your action. We just simply add it to the following enum:  export enum ActionId { LastRemote = 'lastRemote', LastDVE = 'lastDVE', // added new id: GFXStep = 'GFXStep', }   packages\\blueprints\\src\\base\\showstyle\\executeActions\\actionDefinitions.ts  ","version":"Next","tagName":"h2"},{"title":"Step 2: Create a global action to step through the graphic​","type":1,"pageTitle":"Creating a Global AdLib Action","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions#step-2-create-a-global-action-to-step-through-the-graphic","content":" We now need to define the action in our blueprint, this happens in getGlobalActions(). This function returns all global actions for the rundown.  An example of a simple Global AdLib Action  { actionId: ActionId.GFXStep, userData: {}, userDataManifest: {}, display: { label: t('Control Graphic Step'), sourceLayerId: SourceLayer.GFX, outputLayerId: getOutputLayerForSourceLayer(SourceLayer.GFX), }, triggerModes: [], externalId: ingestRundown.externalId, }   packages\\blueprints\\src\\base\\showstyle\\rundown\\globalActions.ts  ","version":"Next","tagName":"h2"},{"title":"Step 3: Execution logic​","type":1,"pageTitle":"Creating a Global AdLib Action","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions#step-3-execution-logic","content":" Now we need to define what our action does, when we trigger it.  In executeAction() we can forward our action to our execution logic:  if (actionId === ActionId.LastRemote) { await executeLastOnSourceLayer(context, SourceLayer.Remote) } else if (actionId === ActionId.LastDVE) { await executeLastOnSourceLayer(context, SourceLayer.DVE) } // Our new action is executed here: else if (actionId === ActionId.GFXStep) { await executeGraphicNextStep(context) }   packages/blueprints/src/base/showstyle/executeActions/index.ts  And then we can have the actual logic in a separate function:  ","version":"Next","tagName":"h2"},{"title":"For our example we could choose from these approaches:​","type":1,"pageTitle":"Creating a Global AdLib Action","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions#for-our-example-we-could-choose-from-these-approaches","content":" context.updatePieceInstance() update the current piece and timeline object (we used this in the example)add new timeline objects for each step execution, these are still part of the same pieceadd keyframes to the already existing timeline object context.insertPiece() to add a new piece with the new step when advancing the graphic  Optionally a DataStoreAction can be used to fast-track the next slide instead of waiting for the database to update.  Relevant reading on Part and Piece actions: https://github.com/Sofie-Automation/sofie-core/blob/release53/packages/blueprints-integration/src/context/partsAndPieceActionContext.ts  export async function executeGraphicNextStep(context: IActionExecutionContext): Promise&lt;void&gt; { const increment = 1 // we filter for any stepped graphic piece const pieceInstances = await context.getPieceInstances('current') const steppedPieceInstances = pieceInstances.filter( (piece) =&gt; (piece.piece.content as unknown as WithTimeline&lt;NoraContent&gt;).step ) // we execute the action for each of them for (const piece of steppedPieceInstances) { const content = piece.piece.content as unknown as WithTimeline&lt;NoraContent&gt; if (content.step) { const { count, current } = content.step newStep = Math.min(newStep, count) await context.updatePieceInstance(piece._id, { ...piece.piece, content: { ...content, // update step data step: { ...content.step, current: newStep }, /* If needed modify the timelineObjects too. timelineObjects: content.timelineObjects.map((tlObj) =&gt; ({ ...tlObj, content: { ...tlObj.content, data: (tlObj.content as any).data ? { ...(tlObj.content as any).data, currentStep: content.step ? newStep : undefined } : undefined, }, })), */ }, }) } } }   packages/blueprints/src/base/showstyle/executeActions/steppedGraphicExample.ts  ","version":"Next","tagName":"h3"},{"title":"Result​","type":1,"pageTitle":"Creating a Global AdLib Action","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions#result","content":"  ","version":"Next","tagName":"h2"},{"title":"TSR Actions","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions","content":"","keywords":"","version":"Next"},{"title":"Introduction to TSR Actions​","type":1,"pageTitle":"TSR Actions","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions#introduction-to-tsr-actions","content":" A TSR Action is a method which is executed inside of a TSR integration. The method can be called upon from Sofie, and subsequently Blueprints Adlib Actions.  ","version":"Next","tagName":"h2"},{"title":"Why do they exist?​","type":1,"pageTitle":"TSR Actions","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions#why-do-they-exist","content":" The main way to control devices (through TSR integrations) in Sofie is via the Timeline. By defining a time-based &quot;State&quot; in blueprints, the TSR can diff the target State compared to the current State at the time of playout, and generate commands to send. This is powerful since it allows Sofie (and blueprints) to not have to take into account the &quot;current state&quot; of the controlled device, and instead focus on the desired state at the time of playout. It also decouples the TSR device from Sofie/Blueprints on a &quot;time-sensitiveness&quot; level, since it allows Sofie to not have to be as time-sensitive as the TSR device and increases the likelihood of commands being sent at the correct time.  For certain operations though, the time sensitivity is not important, and there is no state to be diffed. Some example operations can be &quot;Restart a device&quot;, &quot;Clear all channels&quot;, &quot;Send a custom HTTP request&quot; or &quot;Retrieve some data&quot;. It is for these operations that TSR Actions exist. TSR Actions are often being used in these ways during onRundownActivate and onRundownDeActivate, to reset and prepare the system for a show or to perform some cleanup.  ","version":"Next","tagName":"h3"},{"title":"A few words of caution​","type":1,"pageTitle":"TSR Actions","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions#a-few-words-of-caution","content":" It can be tempting to design a TSR device to ONLY expose TSR Actions, and not use the Timeline at all. This is (often) not recommended, as if goes agains one of the core design philosophies of Sofie - the &quot;state-based approach&quot;. In general, if an &quot;action&quot; can be considered to modify a trackable state of a device (for example: the &quot;play&quot; and &quot;stop&quot; actions modifies the playing status of a video player), it should be defined as a state in TSR and controlled via the Timeline, and not be a TSR Action.  ","version":"Next","tagName":"h3"},{"title":"How do define a TSR action​","type":1,"pageTitle":"TSR Actions","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions#how-do-define-a-tsr-action","content":" https://github.com/Sofie-Automation/sofie-timeline-state-resolver/tree/main/packages/timeline-state-resolver/src/integrations/abstract  Define the method to be executed at the TSR integration. ref: https://github.com/Sofie-Automation/sofie-timeline-state-resolver/blob/release52/packages/timeline-state-resolver/src/integrations/abstract/index.ts#L31Define the action in the TSR integration schema ref: https://github.com/Sofie-Automation/sofie-timeline-state-resolver/blob/release52/packages/timeline-state-resolver/src/integrations/abstract/%24schemas/actions.json#L5Run yarn generate-schema-types to generate the TypeScript types for the action schema in timeline-state-resolver-types folder  ","version":"Next","tagName":"h2"},{"title":"How to execute a TSR action from an Adlib Action​","type":1,"pageTitle":"TSR Actions","url":"/sofie-demo-blueprints/docs/adlibs/tsr_actions#how-to-execute-a-tsr-action-from-an-adlib-action","content":" Here is an example for how to execute a TSR Action from within a Blueprint Adlib Action:  import { TSR, IRundownActivationContext } from '@sofie-automation/blueprints-integration' export async function onMyAdlibAction(context: IActionExecutionContext): Promise&lt;void&gt; { // Get a list of the available TSR devices: const devices = await context.listPlayoutDevices() // Pick a certain device (or just hardcode the deviceId if you know it): const myDevice = devices.find((device) =&gt; device.deviceType === TSR.DeviceType.CASPARCG) if (myDevice) { // execute the TSR Action const result = await context.executeTSRAction(myDevice.deviceId, TSR.CasparCGActions.ClearAllChannels, { // payload }) if (result.result === TSR.ActionExecutionResultCode.Ok) { result.resultData // This is the result data, if any } else if (result.result === TSR.ActionExecutionResultCode.Error) { // handle error result.response result.resultData // This is the result data, if any } else if (result.result === TSR.ActionExecutionResultCode.IgnoredNotRelevant) { // IgnoredNotRelevant can be returned from the TSR Action if the action was not relevant and therefore ignored } } }  ","version":"Next","tagName":"h2"},{"title":"Intro","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/intro","content":"","keywords":"","version":"Next"},{"title":"Installation and Configuration​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#installation-and-configuration","content":" See the README for step-by-step instructions.  ","version":"Next","tagName":"h2"},{"title":"Terminology​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#terminology","content":" ","version":"Next","tagName":"h2"},{"title":"Rundown​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#rundown","content":" A list of Segments that define a full show from start to finish.  ","version":"Next","tagName":"h3"},{"title":"Segment​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#segment","content":" A list of Parts laid out on a timeline that define a specific portion of the show from start to finish. It is possible to &quot;adlib&quot; and deviate from this list by modifying or skipping Parts on-the-fly. Segments can also be skipped.  ","version":"Next","tagName":"h3"},{"title":"Part​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#part","content":" A Part is a group of Pieces that together form a complete scene. Pieces in Parts don't all have to start and end at the same time. Parts can be skipped or adlibbed.  ","version":"Next","tagName":"h3"},{"title":"Piece​","type":1,"pageTitle":"Intro","url":"/sofie-demo-blueprints/docs/intro#piece","content":" A Piece is the smallest building block of a Sofie rundown. It defines a specific aspect of what should be happening in the show at that exact moment, such as which camera to show, which microhpones to unmute, and which graphics to play. Pieces can have a fixed duration or they can be &quot;infinite&quot;, in which case they will only end when the operator performs a Take to move to the next Part. ","version":"Next","tagName":"h3"},{"title":"Piece Types","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/piece_types","content":"","keywords":"","version":"Next"},{"title":"Camera​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#camera","content":" A Camera Piece shows the specified camera on-air.  ","version":"Next","tagName":"h2"},{"title":"Video​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#video","content":" A Video Piece shows the specified video clip (VT) on-air.  ","version":"Next","tagName":"h2"},{"title":"Remote​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#remote","content":" A Remote Piece shows a remote video feed, such as a Skype interviewee or on-location reporter, on-air.  ","version":"Next","tagName":"h2"},{"title":"Lower Third​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#lower-third","content":" A Lower Third Piece overlays a lower third graphic on top of the on-air content.    ","version":"Next","tagName":"h2"},{"title":"Split / DVE​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#split--dve","content":" A Split Piece is used to set up a DVE to show more than one camera, remote, or VT at a time.  ","version":"Next","tagName":"h2"},{"title":"Ticker​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#ticker","content":" A Ticker Piece overlays a ticker graphic along the bottom of the on-air content.    ","version":"Next","tagName":"h2"},{"title":"Studio Guest​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#studio-guest","content":" A Studio Guest Piece is used to automatically unmute and re-mute a guest's microphone via Sisyfos.  ","version":"Next","tagName":"h2"},{"title":"Head​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#head","content":" A Head Piece overlays a headline graphic on the bottom left of the on-air content.    ","version":"Next","tagName":"h2"},{"title":"Live Strap​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#live-strap","content":" A Live Strap Piece overlays a two-line informational graphic in the top left, often used to show the current location as well as a &quot;LIVE&quot; indicator.    ","version":"Next","tagName":"h2"},{"title":"Fullscreen​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#fullscreen","content":" A Fullscreen Piece displays a fullscreen image.    ","version":"Next","tagName":"h2"},{"title":"Graphic​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#graphic","content":" A bare-bones graphic piece type only used as an example in the code.  ","version":"Next","tagName":"h2"},{"title":"Stepped Graphic​","type":1,"pageTitle":"Piece Types","url":"/sofie-demo-blueprints/docs/piece_types#stepped-graphic","content":" A bare-bones graphic piece type extending the piece type above to demonstrate the stepped graphic features of Sofie UI. ","version":"Next","tagName":"h2"},{"title":"Part Types","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/part_types","content":"","keywords":"","version":"Next"},{"title":"Camera​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#camera","content":" Camera Parts feature a fullscreen camera with optional graphics overlaid. A Camera Part consists of the following:  1 Camera Piece1 Audio Piece (autogenerated)Optional Script PieceOptional Graphics PiecesOptional Studio Guest PiecesOptional VT Pieces  The graphics, VTs, and camera input can be adlibbed.  ","version":"Next","tagName":"h2"},{"title":"DVE (Digital Video Effect)​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#dve-digital-video-effect","content":" DVE Parts feature more than one video feed, displayed in a split-screen format. A DVE Part consists of the following:  1 Split Piece1 Camera Piece1 Remote Piece  The Graphics, VTs, and video sources used in the DVE boxes can be adlibbed.  ","version":"Next","tagName":"h2"},{"title":"GFX (Graphics)​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#gfx-graphics","content":" GFX Parts feature a fullscreen graphic with optional graphics overlaid. A GFX Part consists of the following:  1 Graphics Piece (specifically the Fullscreen graphic)Optional Script PieceOptional Graphics PiecesOptional VT Pieces  The Graphics and VTs can be adlibbed.  ","version":"Next","tagName":"h2"},{"title":"Remote​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#remote","content":" Remote Parts feature a fullscreen remote camera with optional graphics overlaid and VTs spliced in. A Remote Part consists of the following:  1 Remote PieceOptional VT PieceOptional Graphics PiecesOptional VT Pieces  The Graphics and VTs can be adlibbed.  ","version":"Next","tagName":"h2"},{"title":"Titles​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#titles","content":" Titles Parts feature a VT that introduces the program. A Titles Part consists of the following:  1 VT Piece (autogenerated)1 Audio Bed Piece (autogenerated)Optional Script Piece  ","version":"Next","tagName":"h2"},{"title":"VO (Voice Over)​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#vo-voice-over","content":" VO Parts feature a VT with optional graphics overlaid. VO Parts also leave one or more microphones unmuted so that A VO Part consists of the following:  1 VT PieceOptional Script PieceOptional Graphics pieces  ","version":"Next","tagName":"h2"},{"title":"VT (Video Tape)​","type":1,"pageTitle":"Part Types","url":"/sofie-demo-blueprints/docs/part_types#vt-video-tape","content":" VT Parts feature a video clip with optional graphics overlaid, with audio from the VT itself. A VT Part consists of the following:  1 VT PieceOptional Script PieceOptional Graphics Pieces  The Graphics can be adlibbed. ","version":"Next","tagName":"h2"},{"title":"Rundown Baseline","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/rundown_baseline","content":"Rundown Baseline The Rundown Baseline tells Sofie how the hardware in the studio should be configured when &quot;at rest&quot; (for example, when the Rundown in question is active but not yet playing). The Demo Blueprints' Rundown Baseline does the following: Configures a few ATEM SuperSource properties, such as the background art and boxesConfigures the ATEM DSK used for GraphicsConfigures the ATEM AUX outputsConfigures the vMix overlay graphics inputConfigures the CasparCG clip player previewConfigures the Sisyfos audio channels","keywords":"","version":"Next"},{"title":"Creating Piece Types","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/piece_types/creating_piece_types","content":"","keywords":"","version":"Next"},{"title":"Create a new ObjectType in the blueprints​","type":1,"pageTitle":"Creating Piece Types","url":"/sofie-demo-blueprints/docs/piece_types/creating_piece_types#create-a-new-objecttype-in-the-blueprints","content":" In packages\\blueprints\\src\\common\\definitions\\objects.ts create a new ObjectType in the ObjectType enum:    ","version":"Next","tagName":"h2"},{"title":"Proof of concept parsing in the blueprints:​","type":1,"pageTitle":"Creating Piece Types","url":"/sofie-demo-blueprints/docs/piece_types/creating_piece_types#proof-of-concept-parsing-in-the-blueprints","content":" We essentially treat the stepped graphic as a sub-type of a Graphic object for the purposes of this example.  For this to work we first need to accept it as a valid graphic object so it can be parsed correctly in a Graphics part.    packages\\blueprints\\src\\base\\showstyle\\sofie-editor-parsers\\index.ts  We now have to also accept it during the parsing of the part:    packages\\blueprints\\src\\base\\showstyle\\sofie-editor-parsers\\gfx.ts  Create simple types, we only have a stepCount property here because of the Rundown Editor's limitations. Ideally we'd ingest a NoraContentSteps as a step property that is already defined in Sofie so if you want to implement stepped graphics we suggest looking into that.  export interface GraphicObjectBase extends BaseObject { objectType: ObjectType.Graphic | ObjectType.SteppedGraphic adlibVariant?: string } export interface SteppedGraphicObject extends GraphicObjectBase { objectType: ObjectType.SteppedGraphic attributes: SteppedGraphicObjectAttributes } export interface SteppedGraphicObjectAttributes extends GraphicObjectAttributes { stepCount: number [key: string]: string | number | boolean | undefined }   packages\\blueprints\\src\\common\\definitions\\objects.ts  Finally for the Sofie UI to render it as a stepped piece we need to return a piece with a step property on it's contents.  This can be skipped if you don't need to show steps for your pieces.  Here the step property has to be the type of NoraContentSteps. The content of your pieces could also differ based on your use-case.    packages\\blueprints\\src\\base\\showstyle\\helpers\\graphics.ts ","version":"Next","tagName":"h2"},{"title":"Studio Baseline","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/studio_baseline","content":"Studio Baseline The Studio Baseline tells Sofie how the hardware in the studio should be configured when &quot;at rest&quot; (for example, when no Rundowns are active). The Demo Blueprints' Studio Baseline mutes all audio channels and configures the ATEM Aux outputs based on the Studio's Blueprint Configuration values.","keywords":"","version":"Next"},{"title":"Trigger modes and dynamic data in AdLib Actions","type":0,"sectionRef":"#","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data","content":"","keywords":"","version":"Next"},{"title":"What is a trigger mode?​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#what-is-a-trigger-mode","content":" Trigger modes are alternate ways of executing an AdLib Action. They show up as options when right-clicking an AdLib Action in the shelf. They are also exposed over the LSG as the actionType and can be used through the REST API as the actionType property.  ","version":"Next","tagName":"h2"},{"title":"Trigger modes in blueprints​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#trigger-modes-in-blueprints","content":" When defining a IBlueprintActionManifest you can add an optional triggerModes property which is an array of IBlueprintActionTriggerMode objects.  Example Action Manifest with two trigger modes:  { actionId: ActionId.GFXStep, userData: {}, userDataManifest: {}, display: { label: t('Control Graphic Step'), sourceLayerId: SourceLayer.GFX, outputLayerId: getOutputLayerForSourceLayer(SourceLayer.GFX), }, triggerModes: [ { data: 'next', display: { _rank: 0, label: t('Next Slide'), description: t('Advance the graphic to the next step'), }, }, { data: 'prev', display: { _rank: 1, label: t('Previous Slide'), description: t('Change the graphic to the previous step'), }, }, ], externalId: ingestRundown.externalId, }   packages/blueprints/src/base/showstyle/executeActions/steppedGraphicExample.ts  ","version":"Next","tagName":"h2"},{"title":"Trigger modes in Sofie UI (shelf)​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#trigger-modes-in-sofie-ui-shelf","content":" The trigger modes will already show up in Sofie UI after reloading the rundown data.    ","version":"Next","tagName":"h2"},{"title":"Trigger modes in Trigger system (key binding and/or streamdeck over input gateway)​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#trigger-modes-in-trigger-system-key-binding-andor-streamdeck-over-input-gateway","content":" Triggers in the Trigger system can be created by the blueprints during migrations or can be created using in Sofie UI's Settings menu.https://sofie-automation.github.io/sofie-core/docs/user-guide/configuration/settings-view#action-triggers-1  Example hotkey/streamdeck trigger in the Sofie UI:    The same trigger as you would declare it in the blueprints:  export function createAdLibHotkeyExample(): IBlueprintTriggeredActions { return { _id: 'custom_adLib_hotkey_example', _rank: rankCounter++ * 1000, actions: { [PlayoutActions.adlib]: { action: PlayoutActions.adlib, arguments: { triggerMode: 'prev' }, filterChain: [ { object: 'view', }, { object: 'adLib', field: 'label', value: ['Control Graphic Step'], }, ].filter(Boolean) as (IRundownPlaylistFilterLink | IGUIContextFilterLink | IAdLibFilterLink)[], }, }, triggers: { ['Hotkey trigger']: { type: TriggerType.hotkey, keys: 'L', up: false, }, ['Device trigger']: { type: TriggerType.device, deviceId: 'device0', triggerId: '7 ↧', // on release of streamdeck button #7 connected via input gateway }, }, name: 'Custom Adlib from Blueprint', } }   packages/blueprints/src/base/showstyle/executeActions/steppedGraphicExample.ts  By adding the above object to the array returned by getTriggeredActions in packages\\blueprints\\src\\base\\showstyle\\applyconfig\\triggered-actions.ts (Demo Blueprints) and applying the new showstyle config in Sofie UI after importing the new Blueprint: Settings ⇒ Select your Showstyle ⇒ Blueprint Configuration ⇒ Fix Up Config ⇒ Validate and Apply Config, the new global shortcut will become available.  ","version":"Next","tagName":"h2"},{"title":"Trigger modes over API​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#trigger-modes-over-api","content":" To use Trigger Modes form the REST API you need to specify the actionType property on the body of the request.  The correct adLibId can be obtained using the Live Status Gateway under the adLibs topic  Example request:  const options = { method: 'POST', headers: { 'Access-Control-Request-Headers': 'content-type', 'Access-Control-Request-Method': 'POST', 'Content-Type': 'application/json', }, body: JSON.stringify({ adLibId: 'mLwUbMWgpVw0QlgKWiNJ09da6PM_', // the ID of your AdLib actionType: 'prev', // triggerMode (e.g. &quot;prev&quot; or &quot;next&quot;) }), } fetch('http://localhost:3000/api/v1.0/playlists/4HU7AFfcs7C4Noma30oxGFg3ZxE_/execute-adlib', options) .then((response) =&gt; response.json()) .then((response) =&gt; console.log(response)) .catch((err) =&gt; console.error(err))   ","version":"Next","tagName":"h2"},{"title":"Custom payloads over the API​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#custom-payloads-over-the-api","content":" You can send custom payloads over the API as well, providing more control over the executed action.  We recommend declaring a userDataManifest for the AdLib Action since this manifest/schema is published using the Live Status Gateway for external applications to programmatically create UIs and API calls. We also recommend to validate the objects received in your action as Sofie Core doesn't validate the payload.  There is a planned feature in Sofie UI to generate fields for the user to edit the AdLib before executing it. Sofie UI currently doesn't support this feature, but it will depend on the userDataManifest.  { actionId: ActionId.GFXStep, userData: {}, userDataManifest: { optionsSchema: JSONBlobStringify({ $schema: 'http://json-schema.org/draft-04/schema#', type: 'object', properties: { test: { type: 'string', }, }, required: ['test'], }), }, display: { label: t('Control Graphic Step'), sourceLayerId: SourceLayer.GFX, outputLayerId: getOutputLayerForSourceLayer(SourceLayer.GFX), } externalId: ingestRundown.externalId, }   packages/blueprints/src/base/showstyle/executeActions/steppedGraphicExample.ts  To send custom data with a request you do so using the adlibOptions property which should follow the schema described in userDataManifest.  const options = { method: 'POST', headers: { 'Access-Control-Request-Headers': 'content-type', 'Access-Control-Request-Method': 'POST', 'Content-Type': 'application/json', }, body: JSON.stringify({ adLibId: 'mLwUbMWgpVw0QlgKWiNJ09da6PM_', // the ID of your AdLib adlibOptions: { // This is an example an object following the schema we declared above test: 'Custom string payload here', }, }), } fetch('http://localhost:3000/api/v1.0/playlists/4HU7AFfcs7C4Noma30oxGFg3ZxE_/execute-adlib', options) .then((response) =&gt; response.json()) .then((response) =&gt; console.log(response)) .catch((err) =&gt; console.error(err))   ","version":"Next","tagName":"h2"},{"title":"How to consume these in the blueprints​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#how-to-consume-these-in-the-blueprints","content":" This example implements an AdLibAction that increments and decrements steps of a stepped Graphic piece with the option to jump to a specific step.  export async function executeAction( context: IActionExecutionContext, _playoutPersistentState: BlueprintPlayoutPersistentStore&lt;unknown&gt;, actionId0: string, _userData: ActionUserData, triggerMode?: string, _privateData?: unknown, _publicData?: unknown, actionOptions?: { [key: string]: any } ): Promise&lt;void&gt; { const actionId = actionId0 as ActionId if (actionId === ActionId.GFXNextStep) { await executeGraphicNextStep(context, triggerMode, actionOptions as ExampleGFXStepActionOptions) } }   packages/blueprints/src/base/showstyle/executeActions/index.ts  type ExampleGFXStepActionOptions = { increment: number jumpTo: number | undefined } export async function executeGraphicNextStep( context: IActionExecutionContext, triggerMode?: string, actionOptions: ExampleGFXStepActionOptions = { increment: 1 } ): Promise&lt;void&gt; // we filter for any stepped graphic piece const pieceInstances = await context.getPieceInstances('current') const steppedPieceInstances = pieceInstances.filter( (piece) =&gt; (piece.piece.content as unknown as WithTimeline&lt;NoraContent&gt;).step ) // we execute the action for each of them for (const piece of steppedPieceInstances) { const content = piece.piece.content as unknown as WithTimeline&lt;NoraContent&gt; if (content.step) { const { count, current } = content.step // determine increment let increment = actionOptions?.increment ?? 1 // fall back to 1 if (triggerMode === ExampleGFXStepActionTriggerModes.PREV) increment = -increment // calculate new step let newStep: number if (actionOptions?.jumpTo !== undefined) { // jump to specific step if specified newStep = actionOptions.jumpTo } else { newStep = current + increment } // and keep it between the bounds of available steps newStep = Math.max(1, Math.min(newStep, count)) await context.updatePieceInstance(piece._id, { ...piece.piece, content: { ...content, // update step data step: { ...content.step, current: newStep }, }, }) } } }   ","version":"Next","tagName":"h2"},{"title":"Result​","type":1,"pageTitle":"Trigger modes and dynamic data in AdLib Actions","url":"/sofie-demo-blueprints/docs/adlibs/adlib_actions/trigger_modes_and_dynamic_data#result","content":"    ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}